{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNhGgigj0az7nTys1QvpiJY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import files\n","uploaded = files.upload()  # 一次性全选你的 14 个 CSV\n","print(\"已上传：\", list(uploaded.keys()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":560},"id":"O_blMMR61WOB","executionInfo":{"status":"ok","timestamp":1756806808639,"user_tz":-480,"elapsed":201034,"user":{"displayName":"Luke Z","userId":"13278367682874279250"}},"outputId":"da810265-97c5-4923-ad49-56f4e40bd4f6"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-f5ded07b-2a41-4bb2-b560-ae54091bae95\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-f5ded07b-2a41-4bb2-b560-ae54091bae95\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 异构GA_2.csv to 异构GA_2.csv\n","Saving 异构DE_2.csv to 异构DE_2.csv\n","Saving 异构DE_1.csv to 异构DE_1.csv\n","Saving 异构GA_1.csv to 异构GA_1.csv\n","Saving 4岛DE_4.csv to 4岛DE_4.csv\n","Saving 4岛DE_3.csv to 4岛DE_3.csv\n","Saving 4岛DE_2.csv to 4岛DE_2.csv\n","Saving 4岛DE_1.csv to 4岛DE_1.csv\n","Saving 4岛GA_4.csv to 4岛GA_4.csv\n","Saving 4岛GA_3.csv to 4岛GA_3.csv\n","Saving 4岛GA_2.csv to 4岛GA_2.csv\n","Saving 4岛GA_1.csv to 4岛GA_1.csv\n","Saving 非岛屿模型单DE.csv to 非岛屿模型单DE.csv\n","Saving 非岛屿模型单GA.csv to 非岛屿模型单GA.csv\n","已上传： ['异构GA_2.csv', '异构DE_2.csv', '异构DE_1.csv', '异构GA_1.csv', '4岛DE_4.csv', '4岛DE_3.csv', '4岛DE_2.csv', '4岛DE_1.csv', '4岛GA_4.csv', '4岛GA_3.csv', '4岛GA_2.csv', '4岛GA_1.csv', '非岛屿模型单DE.csv', '非岛屿模型单GA.csv']\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cMKvzh7u04nx","executionInfo":{"status":"ok","timestamp":1756806843381,"user_tz":-480,"elapsed":26200,"user":{"displayName":"Luke Z","userId":"13278367682874279250"}},"outputId":"40f25a9b-493f-4474-b5a4-d74c4e1e292a"},"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-2220706836.py:211: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  ax.boxplot(data, labels=labels, showfliers=False, widths=0.55)\n","/tmp/ipython-input-2220706836.py:308: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  ax.boxplot(series, labels=labels, showfliers=False, widths=0.55)\n","/tmp/ipython-input-2220706836.py:308: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  ax.boxplot(series, labels=labels, showfliers=False, widths=0.55)\n"]},{"output_type":"stream","name":"stdout","text":["Done. Figures -> ./figs , tables -> ./out\n"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"\n","Reproduce figures for GA/DE single vs four-island experiments (Rastrigin-7D).\n","\n","How to use in Colab:\n","1) Upload all CSVs to the working directory (same folder as this script), namely:\n","   - 非岛屿模型单GA.csv\n","   - 非岛屿模型单DE.csv\n","   - 4岛GA_1.csv, 4岛GA_2.csv, 4岛GA_3.csv, 4岛GA_4.csv\n","   - 4岛DE_1.csv, 4岛DE_2.csv, 4岛DE_3.csv, 4岛DE_4.csv\n","   - 异构GA_1.csv, 异构GA_2.csv, 异构DE_1.csv, 异构DE_2.csv\n","2) (optional) !pip install lifelines  # if you want the log-rank table\n","3) Run: !python repro_figures.py\n","\"\"\"\n","\n","import os\n","import math\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Optional libs\n","try:\n","    from scipy.stats import norm\n","except Exception as _:\n","    norm = None\n","\n","try:\n","    from lifelines.statistics import logrank_test\n","except Exception:\n","    logrank_test = None\n","\n","# ----------------- IO & utils -----------------\n","\n","def ensure_dir(p):\n","    if not os.path.exists(p):\n","        os.makedirs(p)\n","\n","FIG_DIR = \"figs\"\n","OUT_DIR = \"out\"\n","ensure_dir(FIG_DIR)\n","ensure_dir(OUT_DIR)\n","\n","RUN_KEYS = {\"run\",\"run_id\",\"trial\",\"rep\",\"seed\",\"exp\",\"exp_id\",\"id\",\"ga_run\",\"de_run\",\"实验\",\"实验编号\",\"运行\",\"运行编号\",\"序号\"}\n","GEN_KEYS = {\"generation\",\"gen\",\"iteration\",\"iter\",\"t\",\"代\",\"代数\",\"迭代\",\"迭代数\"}\n","BEST_KEYS = {\"best\",\"fbest\",\"best_so_far\",\"bestsofar\",\"fitness\",\"value\",\"objective\",\"obj\",\"最优\",\"最优值\",\"最佳\",\"目标值\",\"适应度\"}\n","\n","def _pick_col(df, candidates):\n","    cols = [c for c in df.columns if isinstance(c, str)]\n","    low = {c: c.strip().lower() for c in cols}\n","    # exact\n","    for c in cols:\n","        if low[c] in candidates: return c\n","    # substring\n","    for c in cols:\n","        if any(tok in low[c] for tok in candidates): return c\n","    raise ValueError(f\"Cannot find required column among {df.columns.tolist()} using keys={candidates}\")\n","\n","def read_csv_flex(path):\n","    df = pd.read_csv(path)\n","    run_col = _pick_col(df, RUN_KEYS)\n","    gen_col = _pick_col(df, GEN_KEYS)\n","    best_col = _pick_col(df, BEST_KEYS)\n","    d = df[[run_col, gen_col, best_col]].copy()\n","    d.columns = [\"run_id\",\"generation\",\"best\"]\n","    d[\"run_id\"] = pd.to_numeric(d[\"run_id\"], errors=\"coerce\").astype(\"Int64\")\n","    d[\"generation\"] = pd.to_numeric(d[\"generation\"], errors=\"coerce\").astype(\"Int64\")\n","    d[\"best\"] = pd.to_numeric(d[\"best\"], errors=\"coerce\")\n","    d = d.dropna(subset=[\"run_id\",\"generation\",\"best\"]).astype({\"run_id\":int,\"generation\":int,\"best\":float})\n","    return d\n","\n","def track_single(path, lam):\n","    d = read_csv_flex(path).sort_values([\"run_id\",\"generation\"])\n","    d[\"fbest\"] = d.groupby(\"run_id\")[\"best\"].cummin()\n","    d[\"lam\"] = lam\n","    return d[[\"run_id\",\"generation\",\"fbest\",\"lam\"]]\n","\n","def track_islands(paths, lam):\n","    frames=[]\n","    for p in paths:\n","        d = read_csv_flex(p).sort_values([\"run_id\",\"generation\"])\n","        d[\"fbest_i\"] = d.groupby(\"run_id\")[\"best\"].cummin()\n","        frames.append(d[[\"run_id\",\"generation\",\"fbest_i\"]])\n","    raw = pd.concat(frames, ignore_index=True)\n","    sys = raw.groupby([\"run_id\",\"generation\"])[\"fbest_i\"].min().reset_index().rename(columns={\"fbest_i\":\"fbest\"})\n","    sys[\"fbest\"] = sys.groupby(\"run_id\")[\"fbest\"].cummin()\n","    sys[\"lam\"] = lam\n","    return sys\n","\n","def fe_hit_per_run(track, theta, FE_cap):\n","    \"\"\"Return per-run first-hit FE and success flag (right-censor at FE_cap).\"\"\"\n","    lam = int(track[\"lam\"].iloc[0])\n","    out = []\n","    for rid, grp in track.groupby(\"run_id\"):\n","        grp = grp.sort_values(\"generation\")\n","        hit = grp.loc[grp[\"fbest\"] <= theta]\n","        if len(hit) > 0:\n","            g = int(hit[\"generation\"].iloc[0])\n","            fe = g*lam\n","            succ = 1 if fe <= FE_cap else 0\n","            fe = min(fe, FE_cap)\n","        else:\n","            succ = 0\n","            fe = FE_cap\n","        out.append({\"run_id\":rid,\"fe_hit\":fe,\"success\":succ})\n","    return pd.DataFrame(out).sort_values(\"run_id\")\n","\n","def step_ecdf(ax, fe_hits, FE_cap, label, lw=2.5):\n","    \"\"\"Draw step ECDF from per-run first-hit FEs (successes only), bounded by [0,FE_cap].\"\"\"\n","    x = sorted(list(fe_hits.loc[fe_hits[\"success\"]==1, \"fe_hit\"].values))\n","    n = len(fe_hits)\n","    if len(x) == 0:\n","        ax.step([0, FE_cap], [0, 0], where=\"post\", linewidth=lw, label=label)\n","        return\n","    ys = np.arange(1, len(x)+1)/n\n","    xs = [0] + x + [FE_cap]\n","    ys = [0] + list(ys) + [ys[-1]]\n","    ax.step(xs, ys, where=\"post\", linewidth=lw, label=label)\n","\n","def wilson_ci(k, n, z=1.96):\n","    if n == 0:\n","        return (0.0, 0.0)\n","    p = k/n\n","    denom = 1.0 + z**2/n\n","    center = (p + z**2/(2*n))/denom\n","    half = z/denom * math.sqrt(p*(1-p)/n + z**2/(4*n**2))\n","    return (max(0.0, center-half), min(1.0, center+half))\n","\n","def two_prop_z(k1,n1,k2,n2):\n","    if norm is None:\n","        return (np.nan, np.nan)\n","    p_pool = (k1+k2)/(n1+n2) if (n1+n2)>0 else 0.0\n","    se = math.sqrt(p_pool*(1-p_pool)*(1/n1 + 1/n2)) if n1>0 and n2>0 else 0.0\n","    if se == 0:\n","        return (np.nan, np.nan)\n","    z = (k1/n1 - k2/n2)/se\n","    p = 2*(1 - norm.cdf(abs(z)))\n","    return (z, p)\n","\n","# ----------------- Figures -----------------\n","\n","def plot_single_ecdf(ga_track, de_track, FE_cap, theta, out_png):\n","    ga_hits = fe_hit_per_run(ga_track, theta, FE_cap)\n","    de_hits = fe_hit_per_run(de_track, theta, FE_cap)\n","    fig, ax = plt.subplots(figsize=(8.5,4.8))\n","    step_ecdf(ax, ga_hits, FE_cap, label=f\"GA_single (SR@50k={ga_hits['success'].mean():.2f})\", lw=2.8)\n","    step_ecdf(ax, de_hits, FE_cap, label=f\"DE_single (SR@50k={de_hits['success'].mean():.2f})\", lw=2.8)\n","    ax.set_xlim(0, FE_cap)\n","    ax.set_ylim(0, 1.0)\n","    ax.set_xlabel(\"Function evaluations (FEs)\")\n","    ax.set_ylabel(\"Success rate (ECDF)\")\n","    ax.set_title(f\"Single-island ECDF (step) vs FEs at θ = {theta:.0e}\")\n","    ax.axvline(FE_cap, linestyle=\"--\", linewidth=1.5, alpha=0.7)\n","    ax.grid(True, axis=\"both\", linestyle=\"--\", alpha=0.35)\n","    ax.legend(frameon=True)\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","    return ga_hits, de_hits\n","\n","def plot_islands_ecdf(de4_track, het4_track, ga4_track, FE_cap, theta, out_png):\n","    de4_hits = fe_hit_per_run(de4_track, theta, FE_cap)\n","    het4_hits = fe_hit_per_run(het4_track, theta, FE_cap)\n","    ga4_hits = fe_hit_per_run(ga4_track, theta, FE_cap)\n","    fig, ax = plt.subplots(figsize=(8.5,4.8))\n","    step_ecdf(ax, de4_hits, FE_cap, label=\"DE4_sync\", lw=2.6)\n","    step_ecdf(ax, het4_hits, FE_cap, label=\"HET4_sync\", lw=2.6)\n","    step_ecdf(ax, ga4_hits, FE_cap, label=\"GA4_sync\", lw=2.6)\n","    ax.set_xlim(0, FE_cap)\n","    ax.set_ylim(0, 1.0)\n","    ax.set_xlabel(\"Function evaluations (FE)\")\n","    ax.set_ylabel(\"Success rate (ECDF)\")\n","    ax.set_title(f\"Islands — Step ECDF vs FE (θ={theta:.0e}), full 5000 gens ({FE_cap:,} FEs)\")\n","    ax.grid(True, axis=\"both\", linestyle=\"--\", alpha=0.35)\n","    ax.legend(frameon=True)\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","    return de4_hits, het4_hits, ga4_hits\n","\n","def plot_de_single_spaghetti(de_track, out_png):\n","    fig, ax = plt.subplots(figsize=(8.6,4.8))\n","    # spaghetti\n","    for rid, grp in de_track.groupby(\"run_id\"):\n","        ax.plot(grp[\"generation\"], np.log10(np.maximum(grp[\"fbest\"].values, 1e-12)),\n","                linewidth=1.0, alpha=0.35)\n","    # median across runs\n","    gens = sorted(de_track[\"generation\"].unique())\n","    med = []\n","    for g in gens:\n","        med.append(np.median(np.log10(np.maximum(de_track.loc[de_track[\"generation\"]==g, \"fbest\"].values, 1e-12))))\n","    ax.plot(gens, med, linewidth=3.0, alpha=0.9, label=\"Median\", color=\"#b255a0\")\n","    # theta lines\n","    for y, lab in [(-3, r\"$\\theta$=1e-03\"), (-5, r\"$\\theta$=1e-05\"), (-7, r\"$\\theta$=1e-07\")]:\n","        ax.axhline(y, linestyle=\"--\", linewidth=1.5, alpha=0.6, color=\"#d69200\")\n","        ax.text(gens[-1]+30, y, lab, va=\"center\")\n","    ax.set_xlabel(\"Generation\")\n","    ax.set_ylabel(r\"log$_{10}$ (best-so-far)\")\n","    ax.set_title(\"Single DE — best-so-far over generations (30 runs)\")\n","    ax.grid(True, axis=\"both\", linestyle=\"--\", alpha=0.3)\n","    ax.legend()\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","def boxplot_islands_FEhit(de4_hits, het4_hits, ga4_hits, theta, out_png, out_pdf=None):\n","    def succ_only(h): return h.loc[h[\"success\"]==1, \"fe_hit\"].values\n","    data = [succ_only(de4_hits), succ_only(het4_hits), succ_only(ga4_hits)]\n","    labels = [\"DE4_sync\",\"HET4_sync\",\"GA4_sync\"]\n","    fig, ax = plt.subplots(figsize=(8.6,4.8))\n","    ax.boxplot(data, labels=labels, showfliers=False, widths=0.55)\n","    ax.set_ylabel(r\"FE to first hit at $\\theta={}$\".format(f\"{theta:.0e}\"))\n","    ax.set_title(\"First-hit distributions (successes only); 30 runs per group\")\n","    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n","    if out_pdf:\n","        fig.savefig(out_pdf, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","# --------- HET events attribution (micro) ---------\n","\n","def het_events_ga_vs_de(ga_paths, de_paths):\n","    frames = []\n","    for p in ga_paths:\n","        d = read_csv_flex(p).sort_values([\"run_id\",\"generation\"])\n","        d[\"fbest_i\"] = d.groupby(\"run_id\")[\"best\"].cummin()\n","        d[\"type\"] = \"GA_like\"\n","        frames.append(d[[\"run_id\",\"generation\",\"fbest_i\",\"type\"]])\n","    for p in de_paths:\n","        d = read_csv_flex(p).sort_values([\"run_id\",\"generation\"])\n","        d[\"fbest_i\"] = d.groupby(\"run_id\")[\"best\"].cummin()\n","        d[\"type\"] = \"DE_like\"\n","        frames.append(d[[\"run_id\",\"generation\",\"fbest_i\",\"type\"]])\n","    all_i = pd.concat(frames, ignore_index=True)\n","\n","    # System best by (run, generation)\n","    sys = all_i.groupby([\"run_id\",\"generation\"])[\"fbest_i\"].min().reset_index().rename(columns={\"fbest_i\":\"sysbest\"})\n","    sys[\"prev\"] = sys.groupby(\"run_id\")[\"sysbest\"].shift(1)\n","    sys[\"delta\"] = sys[\"prev\"] - sys[\"sysbest\"]\n","    events = sys[(sys[\"delta\"].notna()) & (sys[\"delta\"] > 0)].copy()  # strict improvement\n","\n","    # Attribute credit: islands whose fbest_i equals sysbest at that generation\n","    merged = events.merge(all_i, on=[\"run_id\",\"generation\"], how=\"left\")\n","    merged = merged.loc[np.isclose(merged[\"fbest_i\"], merged[\"sysbest\"], rtol=0, atol=1e-12)]\n","    cnt = merged.groupby([\"run_id\",\"generation\"]).size().reset_index(name=\"contributors\")\n","    merged = merged.merge(cnt, on=[\"run_id\",\"generation\"], how=\"left\")\n","    merged[\"credit\"] = 1.0/merged[\"contributors\"]\n","    # Aggregate by type\n","    agg_count = merged.groupby(\"type\")[\"credit\"].sum().reset_index(name=\"events_credit_sum\")\n","    agg_meandelta = merged.groupby(\"type\")[\"delta\"].mean().reset_index(name=\"mean_delta\")\n","    # Scatter\n","    scatter_df = merged[[\"run_id\",\"generation\",\"delta\",\"type\"]].copy()\n","    return agg_count, agg_meandelta, scatter_df\n","\n","def plot_het_events_bars(agg_count, agg_meandelta, out_count_png, out_mean_png):\n","    fig, ax = plt.subplots(figsize=(8.4,4.6))\n","    ax.bar(agg_count[\"type\"], agg_count[\"events_credit_sum\"])\n","    ax.set_ylabel(\"# of improvement events (credit-summed)\")\n","    ax.set_title(\"HET: Number of global improvements by group\")\n","    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n","    fig.tight_layout()\n","    fig.savefig(out_count_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","    fig, ax = plt.subplots(figsize=(8.4,4.6))\n","    ax.bar(agg_meandelta[\"type\"], agg_meandelta[\"mean_delta\"])\n","    ax.set_ylabel(\"Mean improvement per event (Δ/event)\")\n","    ax.set_title(\"HET: Mean improvement magnitude by group\")\n","    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n","    fig.tight_layout()\n","    fig.savefig(out_mean_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","def plot_het_scatter(scatter_df, out_png):\n","    fig, ax = plt.subplots(figsize=(8.6,4.8))\n","    colors = {\"DE_like\":\"#1f77b4\", \"GA_like\":\"#ff7f0e\"}\n","    for tp, grp in scatter_df.groupby(\"type\"):\n","        ax.scatter(grp[\"generation\"], np.log10(np.maximum(grp[\"delta\"].values, 1e-12)),\n","                   s=9, alpha=0.55, label=tp, marker=\"x\" if tp==\"DE_like\" else \"o\",\n","                   color=colors.get(tp, None))\n","    ax.set_xlabel(\"Generation\")\n","    ax.set_ylabel(r\"log$_{10}(\\Delta$ improvement)\")\n","    ax.set_title(\"HET: Improvement magnitude over time\")\n","    ax.grid(True, linestyle=\"--\", alpha=0.3)\n","    ax.legend()\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","# --------- Anytime summary (log10-gap) ---------\n","\n","def loggap_at_budget(track, FE_budget):\n","    lam = int(track[\"lam\"].iloc[0])\n","    g_star = int(np.floor(FE_budget/lam))\n","    xs = []\n","    for rid, grp in track.groupby(\"run_id\"):\n","        grp = grp.sort_values(\"generation\")\n","        b = grp.loc[grp[\"generation\"]<=g_star, \"fbest\"]\n","        val = float(b.iloc[-1]) if len(b)>0 else float(grp[\"fbest\"].iloc[0])\n","        xs.append({\"run_id\":rid, \"log10_gap\": np.log10(max(val, 1e-12))})\n","    return pd.DataFrame(xs).sort_values(\"run_id\")\n","\n","def boxplot_anytime(data_dict, title, ylabel, out_png):\n","    labels = list(data_dict.keys())\n","    series = [np.asarray(data_dict[k][\"log10_gap\"]) for k in labels]\n","    fig, ax = plt.subplots(figsize=(8.4,4.6))\n","    ax.boxplot(series, labels=labels, showfliers=False, widths=0.55)\n","    ax.set_ylabel(ylabel)\n","    ax.set_title(title)\n","    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.35)\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","# --------- Log-rank on time-to-hit (optional) ---------\n","\n","def pairwise_logrank(fe_hits_dict, FE_cap, out_tex=None):\n","    \"\"\"fe_hits_dict: {label: DataFrame[fe_hit, success]}\"\"\"\n","    if logrank_test is None:\n","        print(\"lifelines not installed; skip log-rank.\")\n","        return None\n","    rows = []\n","    keys = list(fe_hits_dict.keys())\n","    for i in range(len(keys)):\n","        for j in range(i+1, len(keys)):\n","            a, b = keys[i], keys[j]\n","            da, db = fe_hits_dict[a], fe_hits_dict[b]\n","            T_a = da[\"fe_hit\"].values\n","            E_a = da[\"success\"].values.astype(int)\n","            T_b = db[\"fe_hit\"].values\n","            E_b = db[\"success\"].values.astype(int)\n","            res = logrank_test(T_a, T_b, event_observed_A=E_a, event_observed_B=E_b)\n","            rows.append({\"comparison\": f\"{a} vs {b}\", \"p\": res.p_value})\n","    df = pd.DataFrame(rows)\n","    if out_tex:\n","        with open(out_tex, \"w\", encoding=\"utf-8\") as f:\n","            f.write(\"\\\\begin{table}[t]\\n\\\\centering\\n\")\n","            f.write(\"\\\\caption{Log-rank tests on time-to-hit (right-censored at %dk FEs).}\\\\n\" % (FE_cap//1000))\n","            f.write(\"\\\\label{tab:logrank}\\n\\\\footnotesize\\n\\\\begin{tabular}{lc}\\n\\\\hline\\n\")\n","            f.write(\"Comparison & $p$ \\\\\\\\\\n\\\\hline\\n\")\n","            for _,r in df.iterrows():\n","                pstr = f\"{r['p']:.2e}\" if r['p']>=1e-15 else \"$<1\\\\times10^{-15}$\"\n","                f.write(f\"{r['comparison']} & {pstr} \\\\\\\\\\n\")\n","            f.write(\"\\\\hline\\n\\\\end{tabular}\\n\\\\end{table}\\n\")\n","    return df\n","\n","# ----------------- Main pipeline -----------------\n","\n","def main():\n","    # File mapping (relative paths)\n","    ga_single_path = \"非岛屿模型单GA.csv\"\n","    de_single_path = \"非岛屿模型单DE.csv\"\n","\n","    ga4_paths = [\"4岛GA_1.csv\",\"4岛GA_2.csv\",\"4岛GA_3.csv\",\"4岛GA_4.csv\"]\n","    de4_paths = [\"4岛DE_1.csv\",\"4岛DE_2.csv\",\"4岛DE_3.csv\",\"4岛DE_4.csv\"]\n","    het_ga_paths = [\"异构GA_1.csv\",\"异构GA_2.csv\"]\n","    het_de_paths = [\"异构DE_1.csv\",\"异构DE_2.csv\"]\n","\n","    # Load tracks\n","    ga_single = track_single(ga_single_path, lam=10)\n","    de_single = track_single(de_single_path, lam=10)\n","\n","    ga4 = track_islands(ga4_paths, lam=40)\n","    de4 = track_islands(de4_paths, lam=40)\n","    het4 = track_islands(het_ga_paths + het_de_paths, lam=40)  # system track for ECDF\n","\n","    # ---- Single ECDFs (0..50k) ----\n","    FE_cap_single = 50_000\n","    for theta in [1e-3, 1e-5, 1e-7]:\n","        out_png = os.path.join(FIG_DIR, f\"ECDF_single_FE_theta_{theta:.0e}_50k.png\").replace(\"+0\", \"\")\n","        plot_single_ecdf(ga_single, de_single, FE_cap_single, theta, out_png)\n","\n","    # ---- Four-island ECDFs (0..200k) ----\n","    FE_cap_islands = 200_000\n","    for theta in [1e-3, 1e-5, 1e-7]:\n","        out_png = os.path.join(FIG_DIR, f\"ISLANDS_ECDF_STEP_FE_theta_{theta:.0e}_FULL200k.png\").replace(\"+0\", \"\")\n","        plot_islands_ecdf(de4, het4, ga4, FE_cap_islands, theta, out_png)\n","\n","    # ---- Single DE spaghetti ----\n","    plot_de_single_spaghetti(de_single, os.path.join(FIG_DIR, \"DE_single_spaghetti_log10.png\"))\n","\n","    # ---- Islands FE_hit box @ theta=1e-5 ----\n","    de4_hits, het4_hits, ga4_hits = plot_islands_ecdf(\n","        de4, het4, ga4, FE_cap_islands, 1e-5,\n","        os.path.join(FIG_DIR, \"ISLANDS_ECDF_for_box_theta_1e-5.png\")\n","    )\n","    boxplot_islands_FEhit(de4_hits, het4_hits, ga4_hits, theta=1e-5,\n","        out_png=os.path.join(FIG_DIR, \"BOX_islands_FEhit_theta1e-5.png\"),\n","        out_pdf=os.path.join(FIG_DIR, \"BOX_islands_FEhit_theta1e-5.pdf\"))\n","\n","    # ---- HET micro: events, mean delta, scatter ----\n","    agg_count, agg_meandelta, scatter_df = het_events_ga_vs_de(het_ga_paths, het_de_paths)\n","    agg_count.to_csv(os.path.join(OUT_DIR, \"HET_events_count.csv\"), index=False)\n","    agg_meandelta.to_csv(os.path.join(OUT_DIR, \"HET_mean_delta.csv\"), index=False)\n","    scatter_df.to_csv(os.path.join(OUT_DIR, \"HET_events_scatter.csv\"), index=False)\n","    plot_het_events_bars(agg_count, agg_meandelta,\n","        out_count_png=os.path.join(FIG_DIR, \"events_count.png\"),\n","        out_mean_png=os.path.join(FIG_DIR, \"mean_delta.png\"))\n","    plot_het_scatter(scatter_df, os.path.join(FIG_DIR, \"scatter_logdelta_vs_gen.png\"))\n","\n","    # ---- Anytime summary ----\n","    # Single @50k\n","    gaps_ga1 = loggap_at_budget(ga_single, 50_000)\n","    gaps_de1 = loggap_at_budget(de_single, 50_000)\n","    pd.concat({\"GA_single\":gaps_ga1.describe(), \"DE_single\":gaps_de1.describe()}, axis=1).to_csv(\n","        os.path.join(OUT_DIR, \"ANYTIME_single_loggap_50k_summary.csv\"))\n","    boxplot_anytime({\"GA_single\":gaps_ga1,\"DE_single\":gaps_de1},\n","        title=r\"Anytime log$_{10}$-gap at 50k FEs (single-island)\",\n","        ylabel=r\"log$_{10}$(best-so-far)\",\n","        out_png=os.path.join(FIG_DIR, \"ANYTIME_single_loggap_50k.png\"))\n","    # Islands @30k (pre-saturation)\n","    gaps_de4 = loggap_at_budget(de4, 30_000)\n","    gaps_het4 = loggap_at_budget(het4, 30_000)\n","    gaps_ga4 = loggap_at_budget(ga4, 30_000)\n","    pd.concat({\"DE4_sync\":gaps_de4.describe(), \"HET4_sync\":gaps_het4.describe(), \"GA4_sync\":gaps_ga4.describe()}, axis=1).to_csv(\n","        os.path.join(OUT_DIR, \"ANYTIME_islands_loggap_30k_summary.csv\"))\n","    boxplot_anytime({\"DE4_sync\":gaps_de4,\"HET4_sync\":gaps_het4,\"GA4_sync\":gaps_ga4},\n","        title=r\"Anytime log$_{10}$-gap at 30k FEs (four-island)\",\n","        ylabel=r\"log$_{10}$(system best-so-far)\",\n","        out_png=os.path.join(FIG_DIR, \"ANYTIME_islands_loggap_30k.png\"))\n","\n","    # ---- SR@50k tables (compact Wilson CI) ----\n","    def sr_ci(track, theta, FE_cap):\n","        hits = fe_hit_per_run(track, theta, FE_cap)\n","        k = int(hits[\"success\"].sum()); n = len(hits)\n","        ci = wilson_ci(k,n)\n","        return k, n, k/n, ci\n","    # Single table\n","    rows = []\n","    for theta in [1e-3,1e-5,1e-7]:\n","        k1,n1,sr1,ci1 = sr_ci(ga_single, theta, FE_cap_single)\n","        k2,n2,sr2,ci2 = sr_ci(de_single, theta, FE_cap_single)\n","        rows.append({\"theta\":f\"{theta:.0e}\", \"GA_single\":f\"{sr1:.2f} [{ci1[0]:.2f}, {ci1[1]:.2f}]\",\n","                     \"DE_single\":f\"{sr2:.2f} [{ci2[0]:.2f}, {ci2[1]:.2f}]\"})\n","    pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR,\"single_SR50k_compact.csv\"), index=False)\n","    # Islands table\n","    rows = []\n","    for theta in [1e-3,1e-5,1e-7]:\n","        de_sr = sr_ci(de4, theta, FE_cap_islands)\n","        het_sr = sr_ci(het4, theta, FE_cap_islands)\n","        ga_sr = sr_ci(ga4, theta, FE_cap_islands)\n","        rows.append({\"theta\":f\"{theta:.0e}\",\n","                     \"DE4_sync\":f\"{de_sr[2]:.2f} [{de_sr[3][0]:.2f}, {de_sr[3][1]:.2f}]\",\n","                     \"HET4_sync\":f\"{het_sr[2]:.2f} [{het_sr[3][0]:.2f}, {het_sr[3][1]:.2f}]\",\n","                     \"GA4_sync\":f\"{ga_sr[2]:.2f} [{ga_sr[3][0]:.2f}, {ga_sr[3][1]:.2f}]\"})\n","    pd.DataFrame(rows).to_csv(os.path.join(OUT_DIR,\"islands_SR50k_compact.csv\"), index=False)\n","\n","    # ---- (optional) Pairwise log-rank at theta=1e-5 (200k censor) ----\n","    if logrank_test is not None:\n","        de_hits = fe_hit_per_run(de4, 1e-5, FE_cap_islands)\n","        het_hits = fe_hit_per_run(het4, 1e-5, FE_cap_islands)\n","        ga_hits = fe_hit_per_run(ga4, 1e-5, FE_cap_islands)\n","        pairwise_logrank({\"DE4_sync\":de_hits,\"HET4_sync\":het_hits,\"GA4_sync\":ga_hits},\n","                         FE_cap_islands, out_tex=os.path.join(OUT_DIR,\"logrank_islands_theta1e5.tex\"))\n","\n","    print(\"Done. Figures -> ./figs , tables -> ./out\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}