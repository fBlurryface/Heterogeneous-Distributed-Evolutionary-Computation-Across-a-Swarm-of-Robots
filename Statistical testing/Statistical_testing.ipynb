{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "R9QO8tO_Ysnb",
        "outputId": "56b8d6c2-a744-4174-ddb0-00f89c195059"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-73695a72-d8f6-49f4-86e5-934be6c3cf19\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-73695a72-d8f6-49f4-86e5-934be6c3cf19\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 异构GA_2.csv to 异构GA_2.csv\n",
            "Saving 异构DE_2.csv to 异构DE_2.csv\n",
            "Saving 异构DE_1.csv to 异构DE_1.csv\n",
            "Saving 异构GA_1.csv to 异构GA_1.csv\n",
            "Saving 4岛DE_4.csv to 4岛DE_4.csv\n",
            "Saving 4岛DE_3.csv to 4岛DE_3.csv\n",
            "Saving 4岛DE_2.csv to 4岛DE_2.csv\n",
            "Saving 4岛DE_1.csv to 4岛DE_1.csv\n",
            "Saving 4岛GA_4.csv to 4岛GA_4.csv\n",
            "Saving 4岛GA_3.csv to 4岛GA_3.csv\n",
            "Saving 4岛GA_2.csv to 4岛GA_2.csv\n",
            "Saving 4岛GA_1.csv to 4岛GA_1.csv\n",
            "Saving 非岛屿模型单DE.csv to 非岛屿模型单DE.csv\n",
            "Saving 非岛屿模型单GA.csv to 非岛屿模型单GA.csv\n",
            "已上传： ['异构GA_2.csv', '异构DE_2.csv', '异构DE_1.csv', '异构GA_1.csv', '4岛DE_4.csv', '4岛DE_3.csv', '4岛DE_2.csv', '4岛DE_1.csv', '4岛GA_4.csv', '4岛GA_3.csv', '4岛GA_2.csv', '4岛GA_1.csv', '非岛屿模型单DE.csv', '非岛屿模型单GA.csv']\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # 一次性全选你的 14 个 CSV\n",
        "print(\"已上传：\", list(uploaded.keys()))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# Recompute Appendix IV & V stats (Colab-ready)\n",
        "# =============================================\n",
        "import os, math\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "FILE_DE4 = [\"4岛DE_1.csv\",\"4岛DE_2.csv\",\"4岛DE_3.csv\",\"4岛DE_4.csv\"]\n",
        "FILE_GA4 = [\"4岛GA_1.csv\",\"4岛GA_2.csv\",\"4岛GA_3.csv\",\"4岛GA_4.csv\"]\n",
        "FILE_HET4 = [\"异构DE_1.csv\",\"异构DE_2.csv\",\"异构GA_1.csv\",\"异构GA_2.csv\"]\n",
        "FILE_DE1 = \"非岛屿模型单DE.csv\"\n",
        "FILE_GA1 = \"非岛屿模型单GA.csv\"\n",
        "\n",
        "LAMBDA_EFF_SINGLE = 10\n",
        "LAMBDA_EFF_MULTI  = 40\n",
        "THETAS = [1e-3, 1e-5, 1e-7]\n",
        "SR_BUDGET_FE = 50_000\n",
        "CENSOR_FE    = 200_000\n",
        "\n",
        "OUTDIR = Path(\"outputs\"); OUTDIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "def _assert_exists(paths):\n",
        "    miss = [str(p) for p in paths if not Path(p).exists()]\n",
        "    if miss: raise FileNotFoundError(f\"Missing files: {miss}\")\n",
        "\n",
        "def _read(p): return pd.read_csv(p, encoding=\"utf-8-sig\")\n",
        "\n",
        "def load_island_group(paths, label):\n",
        "    _assert_exists(paths)\n",
        "    dfs=[]\n",
        "    for p in paths:\n",
        "        df=_read(p)[[\"GA_run\",\"Generation\",\"Best\"]].copy()\n",
        "        df=df.rename(columns={\"Best\": Path(p).stem})\n",
        "        dfs.append(df)\n",
        "    out=dfs[0]\n",
        "    for d in dfs[1:]:\n",
        "        out=out.merge(d,on=[\"GA_run\",\"Generation\"],how=\"inner\")\n",
        "    island_cols=[c for c in out.columns if c not in [\"GA_run\",\"Generation\"]]\n",
        "    out=out.sort_values([\"GA_run\",\"Generation\"])\n",
        "    out[\"BestGlobal_inst\"]=out[island_cols].min(axis=1)\n",
        "    out[\"BestGlobal_bsf\"]=out.groupby(\"GA_run\")[\"BestGlobal_inst\"].cummin()\n",
        "    out[\"Config\"]=label\n",
        "    return out[[\"GA_run\",\"Generation\",\"BestGlobal_inst\",\"BestGlobal_bsf\",\"Config\"]]\n",
        "\n",
        "def load_single_island(path,label):\n",
        "    _assert_exists([path])\n",
        "    df=_read(path)[[\"GA_run\",\"Generation\",\"Best\"]].copy()\n",
        "    df=df.rename(columns={\"Best\":\"BestGlobal_inst\"})\n",
        "    df=df.sort_values([\"GA_run\",\"Generation\"])\n",
        "    df[\"BestGlobal_bsf\"]=df.groupby(\"GA_run\")[\"BestGlobal_inst\"].cummin()\n",
        "    df[\"Config\"]=label\n",
        "    return df[[\"GA_run\",\"Generation\",\"BestGlobal_inst\",\"BestGlobal_bsf\",\"Config\"]]\n",
        "\n",
        "DE4=load_island_group(FILE_DE4,\"DE4\")\n",
        "GA4=load_island_group(FILE_GA4,\"GA4\")\n",
        "HET4=load_island_group(FILE_HET4,\"HET4\")\n",
        "DE1=load_single_island(FILE_DE1,\"DE1\")\n",
        "GA1=load_single_island(FILE_GA1,\"GA1\")\n",
        "\n",
        "all_df=pd.concat([DE4,GA4,HET4,DE1,GA1],ignore_index=True)\n",
        "SCALE={\"DE4\":LAMBDA_EFF_MULTI,\"GA4\":LAMBDA_EFF_MULTI,\"HET4\":LAMBDA_EFF_MULTI,\n",
        "       \"DE1\":LAMBDA_EFF_SINGLE,\"GA1\":LAMBDA_EFF_SINGLE}\n",
        "all_df[\"FE\"]=all_df.apply(lambda r:r[\"Generation\"]*SCALE[r[\"Config\"]],axis=1)\n",
        "\n",
        "# -- SR@50k two-proportion z-tests --\n",
        "def sr_counts(df_cfg, theta, budget=SR_BUDGET_FE):\n",
        "    sub=df_cfg[df_cfg[\"FE\"]<=budget].sort_values([\"GA_run\",\"FE\"])\n",
        "    last=sub.groupby(\"GA_run\").tail(1)\n",
        "    succ=int((last[\"BestGlobal_bsf\"]<=theta).sum())\n",
        "    total=last[\"GA_run\"].nunique()\n",
        "    return succ,total\n",
        "\n",
        "def two_prop_z(x1,n1,x2,n2):\n",
        "    if n1==0 or n2==0: return np.nan,np.nan,np.nan,np.nan\n",
        "    p1=x1/n1; p2=x2/n2; p=(x1+x2)/(n1+n2)\n",
        "    se=math.sqrt(p*(1-p)*(1/n1+1/n2))\n",
        "    z=0.0 if se==0 else (p1-p2)/se\n",
        "    Phi=lambda x:0.5*(1+math.erf(x/math.sqrt(2)))\n",
        "    p_two=2*(1-Phi(abs(z)))\n",
        "    return p1,p2,z,p_two\n",
        "\n",
        "PAIRS_PROP=[(\"GA1\",\"DE1\"),(\"DE4\",\"GA4\"),(\"HET4\",\"GA4\"),(\"DE4\",\"HET4\")]\n",
        "rows=[]\n",
        "for th in THETAS:\n",
        "    for a,b in PAIRS_PROP:\n",
        "        da=all_df[all_df[\"Config\"]==a]\n",
        "        db=all_df[all_df[\"Config\"]==b]\n",
        "        x1,n1=sr_counts(da,th); x2,n2=sr_counts(db,th)\n",
        "        p1,p2,z,pv=two_prop_z(x1,n1,x2,n2)\n",
        "        rows.append({\"Theta\":th,\"Pair\":f\"{a} vs {b}\",\n",
        "                     \"x1\":x1,\"n1\":n1,\"x2\":x2,\"n2\":n2,\"z\":z,\"p_two\":pv,\n",
        "                     \"p1\":p1,\"p2\":p2})\n",
        "twoprop_df=pd.DataFrame(rows)\n",
        "twoprop_df.to_csv(OUTDIR/\"verification_twoprop.csv\",index=False)\n",
        "print(\"\\n=== Appendix IV: Two-proportion z-tests (SR@50k) ===\")\n",
        "disp=twoprop_df.copy()\n",
        "disp[\"Theta\"]=disp[\"Theta\"].map({1e-3:\"1e-3\",1e-5:\"1e-5\",1e-7:\"1e-7\"})\n",
        "disp[\"p1(%)\"]=(disp[\"p1\"]*100).round(1); disp[\"p2(%)\"]=(disp[\"p2\"]*100).round(1)\n",
        "print(disp[[\"Theta\",\"Pair\",\"x1\",\"n1\",\"x2\",\"n2\",\"z\",\"p_two\",\"p1(%)\",\"p2(%)\"]]\n",
        "      .to_string(index=False,justify=\"center\",float_format=lambda v:f\"{v:.3g}\"))\n",
        "\n",
        "# -- FEhit log-rank (four-island pairs) --\n",
        "def fehit_vector(df_cfg, theta, censor_fe=CENSOR_FE):\n",
        "    sub=df_cfg[df_cfg[\"FE\"]<=censor_fe].sort_values([\"GA_run\",\"FE\"])\n",
        "    hits=[]\n",
        "    for run,g in sub.groupby(\"GA_run\"):\n",
        "        h=g[g[\"BestGlobal_bsf\"]<=theta]\n",
        "        hits.append(float(h[\"FE\"].iloc[0]) if len(h)>0 else np.nan)\n",
        "    return np.array(hits,float)\n",
        "\n",
        "def logrank_two_sample(times_a,times_b):\n",
        "    a=np.asarray(times_a,float); a=a[~np.isnan(a)]; a.sort()\n",
        "    b=np.asarray(times_b,float); b=b[~np.isnan(b)]; b.sort()\n",
        "    if len(a)==0 or len(b)==0: return 0.0,1.0\n",
        "    uniq=np.unique(np.concatenate([a,b]))\n",
        "    from collections import Counter\n",
        "    ca,cb=Counter(a),Counter(b)\n",
        "    n_a,n_b=len(a),len(b); at_a,at_b=n_a,n_b\n",
        "    Oa=Ea=Va=0.0\n",
        "    for t in uniq:\n",
        "        da,db=ca.get(t,0),cb.get(t,0); d=da+db\n",
        "        if (at_a+at_b)>1 and d>0:\n",
        "            e_a=d*(at_a/(at_a+at_b))\n",
        "            v_a=(at_a*at_b*d*(at_a+at_b-d))/(((at_a+at_b)**2)*(at_a+at_b-1))\n",
        "            Oa+=da; Ea+=e_a; Va+=v_a\n",
        "        at_a-=da; at_b-=db\n",
        "    if Va<=0: return 0.0,1.0\n",
        "    chi2=(Oa-Ea)**2/Va\n",
        "    z=math.sqrt(chi2); Phi=lambda x:0.5*(1+math.erf(x/math.sqrt(2)))\n",
        "    p_two=2*(1-Phi(z))\n",
        "    return chi2,p_two\n",
        "\n",
        "PAIRS_LR=[(\"DE4\",\"HET4\"),(\"DE4\",\"GA4\"),(\"HET4\",\"GA4\")]\n",
        "rows=[]\n",
        "for th in THETAS:\n",
        "    for a,b in PAIRS_LR:\n",
        "        va=fehit_vector(all_df[all_df[\"Config\"]==a],th)\n",
        "        vb=fehit_vector(all_df[all_df[\"Config\"]==b],th)\n",
        "        chi2,p=logrank_two_sample(va,vb)\n",
        "        rows.append({\"Theta\":th,\"Pair\":f\"{a} vs {b}\",\"Chi2\":chi2,\"p_logrank\":p,\n",
        "                     \"n_a\":int(np.isfinite(va).sum()),\"n_b\":int(np.isfinite(vb).sum())})\n",
        "logrank_df=pd.DataFrame(rows)\n",
        "logrank_df.to_csv(OUTDIR/\"verification_logrank.csv\",index=False)\n",
        "\n",
        "print(\"\\n=== Appendix V: Log-rank tests on FEhit (four-island pairs) ===\")\n",
        "disp=logrank_df.copy()\n",
        "disp[\"Theta\"]=disp[\"Theta\"].map({1e-3:\"1e-3\",1e-5:\"1e-5\",1e-7:\"1e-7\"})\n",
        "disp[\"Chi2\"]=disp[\"Chi2\"].map(lambda x: float(f\"{x:.3f}\"))\n",
        "disp[\"p_logrank\"]=disp[\"p_logrank\"].map(lambda x: float(f\"{x:.4g}\"))\n",
        "print(disp[[\"Theta\",\"Pair\",\"n_a\",\"n_b\",\"Chi2\",\"p_logrank\"]]\n",
        "      .to_string(index=False,justify=\"center\"))\n",
        "\n",
        "print(\"\\nSaved CSVs -> ./outputs/:\")\n",
        "for p in sorted(OUTDIR.glob(\"*.csv\")):\n",
        "    print(\" -\", p.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTU_B_wwdJ1a",
        "outputId": "85c2307e-5dae-42aa-b9e2-143b03c4b44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Appendix IV: Two-proportion z-tests (SR@50k) ===\n",
            "Theta     Pair     x1  n1  x2  n2   z    p_two   p1(%)  p2(%)\n",
            " 1e-3  GA1 vs DE1  30  30   0  30 7.75 9.33e-15   100      0 \n",
            " 1e-3  DE4 vs GA4  30  30  30  30    0        1   100    100 \n",
            " 1e-3 HET4 vs GA4  30  30  30  30    0        1   100    100 \n",
            " 1e-3 DE4 vs HET4  30  30  30  30    0        1   100    100 \n",
            " 1e-5  GA1 vs DE1  28  30   0  30 7.25  4.3e-13  93.3      0 \n",
            " 1e-5  DE4 vs GA4  30  30   5  30 6.55 5.89e-11   100   16.7 \n",
            " 1e-5 HET4 vs GA4  30  30   5  30 6.55 5.89e-11   100   16.7 \n",
            " 1e-5 DE4 vs HET4  30  30  30  30    0        1   100    100 \n",
            " 1e-7  GA1 vs DE1  17  30   0  30 4.87 1.11e-06  56.7      0 \n",
            " 1e-7  DE4 vs GA4  30  30   0  30 7.75 9.33e-15   100      0 \n",
            " 1e-7 HET4 vs GA4  30  30   0  30 7.75 9.33e-15   100      0 \n",
            " 1e-7 DE4 vs HET4  30  30  30  30    0        1   100    100 \n",
            "\n",
            "=== Appendix V: Log-rank tests on FEhit (four-island pairs) ===\n",
            "Theta     Pair     n_a  n_b  Chi2    p_logrank \n",
            " 1e-3 DE4 vs HET4  30   30   2.933 8.676000e-02\n",
            " 1e-3  DE4 vs GA4  30   30  25.388 4.689000e-07\n",
            " 1e-3 HET4 vs GA4  30   30  10.935 9.438000e-04\n",
            " 1e-5 DE4 vs HET4  30   30   9.112 2.540000e-03\n",
            " 1e-5  DE4 vs GA4  30   30  69.192 0.000000e+00\n",
            " 1e-5 HET4 vs GA4  30   30  67.572 2.220000e-16\n",
            " 1e-7 DE4 vs HET4  30   30  15.321 9.071000e-05\n",
            " 1e-7  DE4 vs GA4  30   30  71.274 0.000000e+00\n",
            " 1e-7 HET4 vs GA4  30   30  71.236 0.000000e+00\n",
            "\n",
            "Saved CSVs -> ./outputs/:\n",
            " - verification_logrank.csv\n",
            " - verification_twoprop.csv\n"
          ]
        }
      ]
    }
  ]
}